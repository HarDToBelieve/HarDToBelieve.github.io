<dec f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_coding/neteq/sync_buffer.h' l='80' type='void webrtc::SyncBuffer::GetNextAudioInterleaved(size_t requested_len, webrtc::AudioFrame * output)'/>
<doc f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_coding/neteq/sync_buffer.h' l='76'>// Reads |requested_len| samples from each channel and writes them interleaved
  // into |output|. The |next_index_| is updated to point to the sample to read
  // next time. The AudioFrame |output| is first reset, and the |data_|,
  // |num_channels_|, and |samples_per_channel_| fields are updated.</doc>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_coding/neteq/neteq_impl.cc' l='1000' u='c' c='_ZN6webrtc9NetEqImpl16GetAudioInternalEPNS_10AudioFrameEPbNSt3__18optionalINS_5NetEq9OperationEEE'/>
<def f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_coding/neteq/sync_buffer.cc' l='84' ll='95' type='void webrtc::SyncBuffer::GetNextAudioInterleaved(size_t requested_len, webrtc::AudioFrame * output)'/>
