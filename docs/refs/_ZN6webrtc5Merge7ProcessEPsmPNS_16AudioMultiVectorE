<dec f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_coding/neteq/merge.h' l='44' type='size_t webrtc::Merge::Process(int16_t * input, size_t input_length, webrtc::AudioMultiVector * output)'/>
<def f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_coding/neteq/merge.cc' l='46' ll='162' type='size_t webrtc::Merge::Process(int16_t * input, size_t input_length, webrtc::AudioMultiVector * output)'/>
<doc f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_coding/neteq/merge.h' l='39'>// The main method to produce the audio data. The decoded data is supplied in
  // |input|, having |input_length| samples in total for all channels
  // (interleaved). The result is written to |output|. The number of channels
  // allocated in |output| defines the number of channels that will be used when
  // de-interleaving |input|.</doc>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_coding/neteq/neteq_impl.cc' l='1614' u='c' c='_ZN6webrtc9NetEqImpl7DoMergeEPsmNS_12AudioDecoder10SpeechTypeEb'/>
