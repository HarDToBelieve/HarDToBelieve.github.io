<inh f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/rtc_base/ref_count.h' l='54' c='rtc::RefCountInterface'/>
<def f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_processing/include/audio_processing.h' l='177' ll='743'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_processing/include/audio_processing.h' l='781' c='_ZN6webrtc22AudioProcessingBuilder6CreateEv'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_processing/include/audio_processing.h' l='782' c='_ZN6webrtc22AudioProcessingBuilder6CreateERKNS_6ConfigE'/>
<size>8</size>
<doc f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_processing/include/audio_processing.h' l='97'>// The Audio Processing Module (APM) provides a collection of voice processing
// components designed for real-time communications software.
//
// APM operates on two audio streams on a frame-by-frame basis. Frames of the
// primary stream, on which all processing is applied, are passed to
// |ProcessStream()|. Frames of the reverse direction stream are passed to
// |ProcessReverseStream()|. On the client-side, this will typically be the
// near-end (capture) and far-end (render) streams, respectively. APM should be
// placed in the signal chain as close to the audio hardware abstraction layer
// (HAL) as possible.
//
// On the server-side, the reverse stream will normally not be used, with
// processing occurring on each incoming stream.
//
// Component interfaces follow a similar pattern and are accessed through
// corresponding getters in APM. All components are disabled at create-time,
// with default settings that are recommended for most situations. New settings
// can be applied without enabling a component. Enabling a component triggers
// memory allocation and initialization to allow it to start processing the
// streams.
//
// Thread safety is provided with the following assumptions to reduce locking
// overhead:
//   1. The stream getters and setters are called from the same thread as
//      ProcessStream(). More precisely, stream functions are never called
//      concurrently with ProcessStream().
//   2. Parameter getters are never called concurrently with the corresponding
//      setter.
//
// APM accepts only linear PCM audio data in chunks of 10 ms. The int16
// interfaces use interleaved data, while the float interfaces use deinterleaved
// data.
//
// Usage example, omitting error checking:
// AudioProcessing* apm = AudioProcessingBuilder().Create();
//
// AudioProcessing::Config config;
// config.echo_canceller.enabled = true;
// config.echo_canceller.mobile_mode = false;
//
// config.gain_controller1.enabled = true;
// config.gain_controller1.mode =
// AudioProcessing::Config::GainController1::kAdaptiveAnalog;
// config.gain_controller1.analog_level_minimum = 0;
// config.gain_controller1.analog_level_maximum = 255;
//
// config.gain_controller2.enabled = true;
//
// config.high_pass_filter.enabled = true;
//
// config.voice_detection.enabled = true;
//
// apm-&gt;ApplyConfig(config)
//
// apm-&gt;noise_reduction()-&gt;set_level(kHighSuppression);
// apm-&gt;noise_reduction()-&gt;Enable(true);
//
// // Start a voice call...
//
// // ... Render frame arrives bound for the audio HAL ...
// apm-&gt;ProcessReverseStream(render_frame);
//
// // ... Capture frame arrives from the audio HAL ...
// // Call required set_stream_ functions.
// apm-&gt;set_stream_delay_ms(delay_ms);
// apm-&gt;set_stream_analog_level(analog_level);
//
// apm-&gt;ProcessStream(capture_frame);
//
// // Call required stream_ functions.
// analog_level = apm-&gt;recommended_stream_analog_level();
// has_voice = apm-&gt;stream_has_voice();
//
// // Repeat render and capture processing for the duration of the call...
// // Start a new call...
// apm-&gt;Initialize();
//
// // Close the application...
// delete apm;
//</doc>
<fun r='_ZN6webrtc15AudioProcessingD1Ev'/>
<fun r='_ZN6webrtc15AudioProcessing10InitializeEv'/>
<fun r='_ZN6webrtc15AudioProcessing10InitializeERKNS_16ProcessingConfigE'/>
<fun r='_ZN6webrtc15AudioProcessing10InitializeEiiiNS0_13ChannelLayoutES1_S1_'/>
<fun r='_ZN6webrtc15AudioProcessing11ApplyConfigERKNS0_6ConfigE'/>
<fun r='_ZNK6webrtc15AudioProcessing19proc_sample_rate_hzEv'/>
<fun r='_ZNK6webrtc15AudioProcessing25proc_split_sample_rate_hzEv'/>
<fun r='_ZNK6webrtc15AudioProcessing18num_input_channelsEv'/>
<fun r='_ZNK6webrtc15AudioProcessing17num_proc_channelsEv'/>
<fun r='_ZNK6webrtc15AudioProcessing19num_output_channelsEv'/>
<fun r='_ZNK6webrtc15AudioProcessing20num_reverse_channelsEv'/>
<fun r='_ZN6webrtc15AudioProcessing24set_output_will_be_mutedEb'/>
<fun r='_ZN6webrtc15AudioProcessing17SetRuntimeSettingENS0_14RuntimeSettingE'/>
<fun r='_ZN6webrtc15AudioProcessing18PostRuntimeSettingENS0_14RuntimeSettingE'/>
<fun r='_ZN6webrtc15AudioProcessing13ProcessStreamEPKsRKNS_12StreamConfigES5_Ps'/>
<fun r='_ZN6webrtc15AudioProcessing13ProcessStreamEPKPKfRKNS_12StreamConfigES7_PKPf'/>
<fun r='_ZN6webrtc15AudioProcessing20ProcessReverseStreamEPKsRKNS_12StreamConfigES5_Ps'/>
<fun r='_ZN6webrtc15AudioProcessing20ProcessReverseStreamEPKPKfRKNS_12StreamConfigES7_PKPf'/>
<fun r='_ZN6webrtc15AudioProcessing20AnalyzeReverseStreamEPKPKfRKNS_12StreamConfigE'/>
<fun r='_ZNK6webrtc15AudioProcessing18GetLinearAecOutputEN3rtc9ArrayViewINSt3__15arrayIfLm160EEELln4711EEE'/>
<fun r='_ZN6webrtc15AudioProcessing23set_stream_analog_levelEi'/>
<fun r='_ZNK6webrtc15AudioProcessing31recommended_stream_analog_levelEv'/>
<fun r='_ZN6webrtc15AudioProcessing19set_stream_delay_msEi'/>
<fun r='_ZNK6webrtc15AudioProcessing15stream_delay_msEv'/>
<fun r='_ZN6webrtc15AudioProcessing22set_stream_key_pressedEb'/>
<fun r='_ZN6webrtc15AudioProcessing22CreateAndAttachAecDumpERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEExPN3rtc9TaskQueueE'/>
<fun r='_ZN6webrtc15AudioProcessing22CreateAndAttachAecDumpEP7__sFILExPN3rtc9TaskQueueE'/>
<fun r='_ZN6webrtc15AudioProcessing13AttachAecDumpENSt3__110unique_ptrINS_7AecDumpENS1_14default_deleteIS3_EEEE'/>
<fun r='_ZN6webrtc15AudioProcessing13DetachAecDumpEv'/>
<fun r='_ZN6webrtc15AudioProcessing13GetStatisticsEv'/>
<fun r='_ZN6webrtc15AudioProcessing13GetStatisticsEb'/>
<fun r='_ZNK6webrtc15AudioProcessing9GetConfigEv'/>
<smbr r='webrtc::AudioProcessing::kNativeSampleRatesHz' t='int const[4]'/>
<smbr r='webrtc::AudioProcessing::kNumNativeSampleRates' t='const size_t'/>
<smbr r='webrtc::AudioProcessing::kMaxNativeSampleRateHz' t='const int'/>
<smbr r='webrtc::AudioProcessing::kChunkSizeMs' t='const int'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/call/audio_state.h' l='37'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/call/audio_state.h' l='46' c='_ZN6webrtc10AudioState16audio_processingEv'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/api/create_peerconnection_factory.h' l='51' c='_ZN6webrtc27CreatePeerConnectionFactoryEPN3rtc6ThreadES2_S2_NS0_13scoped_refptrINS_17AudioDeviceModuleEEENS3_INS_19AudioEncoderFactoryEEENS3_INS_19Aud1345794'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/media/engine/webrtc_media_engine.h' l='50'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/api/create_peerconnection_factory.cc' l='40' c='_ZN6webrtc27CreatePeerConnectionFactoryEPN3rtc6ThreadES2_S2_NS0_13scoped_refptrINS_17AudioDeviceModuleEEENS3_INS_19AudioEncoderFactoryEEENS3_INS_19Aud1345794'/>
<size>8</size>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/audio/audio_transport_impl.h' l='35' c='_ZN6webrtc18AudioTransportImplC1EPNS_10AudioMixerEPNS_15AudioProcessingEPNS_20AsyncAudioProcessing7FactoryE'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/audio/audio_transport_impl.h' l='82'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/audio/audio_state.h' l='41' c='_ZN6webrtc8internal10AudioState16audio_processingEv'/>
<size>8</size>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/audio/audio_send_stream.cc' l='496' c='_ZNK6webrtc8internal15AudioSendStream8GetStatsEb'/>
<size>8</size>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/audio/audio_state.cc' l='45' c='_ZN6webrtc8internal10AudioState16audio_processingEv'/>
<size>8</size>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_processing/include/audio_frame_proxies.h' l='27' c='_ZN6webrtc17ProcessAudioFrameEPNS_15AudioProcessingEPNS_10AudioFrameE'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_processing/include/audio_frame_proxies.h' l='37' c='_ZN6webrtc24ProcessReverseAudioFrameEPNS_15AudioProcessingEPNS_10AudioFrameE'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/audio/audio_transport_impl.cc' l='51' c='_ZN6webrtc12_GLOBAL__N_119ProcessCaptureFrameEjbbPNS_15AudioProcessingEPNS_10AudioFrameE'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/audio/audio_transport_impl.cc' l='89' c='_ZN6webrtc18AudioTransportImplC1EPNS_10AudioMixerEPNS_15AudioProcessingEPNS_20AsyncAudioProcessing7FactoryE'/>
<size>8</size>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/call/call_config.h' l='45'/>
<size>8</size>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/media/engine/webrtc_voice_engine.h' l='56' c='_ZN7cricket17WebRtcVoiceEngineC1EPN6webrtc16TaskQueueFactoryEPNS1_17AudioDeviceModuleERKN3rtc13scoped_refptrINS1_19AudioEncoderFactoryEEERKNS7_INS1_193986509'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/media/engine/webrtc_voice_engine.h' l='102' c='_ZNK7cricket17WebRtcVoiceEngine3apmEv'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/media/engine/webrtc_voice_engine.h' l='117'/>
<size>8</size>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/media/engine/webrtc_voice_engine.cc' l='251' c='_ZN7cricket17WebRtcVoiceEngineC1EPN6webrtc16TaskQueueFactoryEPNS1_17AudioDeviceModuleERKN3rtc13scoped_refptrINS1_19AudioEncoderFactoryEEERKNS7_INS1_193986509'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/media/engine/webrtc_voice_engine.cc' l='524' c='_ZN7cricket17WebRtcVoiceEngine12ApplyOptionsERKNS_12AudioOptionsE'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/media/engine/webrtc_voice_engine.cc' l='632' c='_ZN7cricket17WebRtcVoiceEngine12StartAecDumpEN6webrtc11FileWrapperEx'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/media/engine/webrtc_voice_engine.cc' l='646' c='_ZN7cricket17WebRtcVoiceEngine11StopAecDumpEv'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/media/engine/webrtc_voice_engine.cc' l='661' c='_ZNK7cricket17WebRtcVoiceEngine3apmEv'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/media/engine/webrtc_voice_engine.cc' l='2326' c='_ZN7cricket23WebRtcVoiceMediaChannel10MuteStreamEjb'/>
<size>8</size>
<ovr f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_processing/audio_processing_impl.h' l='54' c='webrtc::AudioProcessingImpl'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_processing/audio_processing_impl.h' l='54'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_processing/audio_processing_builder_impl.cc' l='23' c='_ZN6webrtc22AudioProcessingBuilder6CreateEv'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_processing/audio_processing_builder_impl.cc' l='28' c='_ZN6webrtc22AudioProcessingBuilder6CreateERKNS_6ConfigE'/>
<size>8</size>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_processing/include/audio_frame_proxies.cc' l='18' c='_ZN6webrtc17ProcessAudioFrameEPNS_15AudioProcessingEPNS_10AudioFrameE'/>
<use f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_processing/include/audio_frame_proxies.cc' l='43' c='_ZN6webrtc24ProcessReverseAudioFrameEPNS_15AudioProcessingEPNS_10AudioFrameE'/>
<size>8</size>
<inh f='webkit/WebKitBuild/Debug/usr/local/include/webrtc/rtc_base/ref_count.h' l='54' c='rtc::RefCountInterface'/>
<def f='webkit/WebKitBuild/Debug/usr/local/include/webrtc/modules/audio_processing/include/audio_processing.h' l='177' ll='743'/>
<use f='webkit/WebKitBuild/Debug/usr/local/include/webrtc/modules/audio_processing/include/audio_processing.h' l='781' c='_ZN6webrtc22AudioProcessingBuilder6CreateEv'/>
<use f='webkit/WebKitBuild/Debug/usr/local/include/webrtc/modules/audio_processing/include/audio_processing.h' l='782' c='_ZN6webrtc22AudioProcessingBuilder6CreateERKNS_6ConfigE'/>
<use f='webkit/WebKitBuild/Debug/usr/local/include/webrtc/call/audio_state.h' l='37'/>
<use f='webkit/WebKitBuild/Debug/usr/local/include/webrtc/call/audio_state.h' l='46' c='_ZN6webrtc10AudioState16audio_processingEv'/>
<use f='webkit/WebKitBuild/Debug/usr/local/include/webrtc/call/call_config.h' l='45'/>
<size>8</size>
<doc f='webkit/WebKitBuild/Debug/usr/local/include/webrtc/modules/audio_processing/include/audio_processing.h' l='97'>// The Audio Processing Module (APM) provides a collection of voice processing
// components designed for real-time communications software.
//
// APM operates on two audio streams on a frame-by-frame basis. Frames of the
// primary stream, on which all processing is applied, are passed to
// |ProcessStream()|. Frames of the reverse direction stream are passed to
// |ProcessReverseStream()|. On the client-side, this will typically be the
// near-end (capture) and far-end (render) streams, respectively. APM should be
// placed in the signal chain as close to the audio hardware abstraction layer
// (HAL) as possible.
//
// On the server-side, the reverse stream will normally not be used, with
// processing occurring on each incoming stream.
//
// Component interfaces follow a similar pattern and are accessed through
// corresponding getters in APM. All components are disabled at create-time,
// with default settings that are recommended for most situations. New settings
// can be applied without enabling a component. Enabling a component triggers
// memory allocation and initialization to allow it to start processing the
// streams.
//
// Thread safety is provided with the following assumptions to reduce locking
// overhead:
//   1. The stream getters and setters are called from the same thread as
//      ProcessStream(). More precisely, stream functions are never called
//      concurrently with ProcessStream().
//   2. Parameter getters are never called concurrently with the corresponding
//      setter.
//
// APM accepts only linear PCM audio data in chunks of 10 ms. The int16
// interfaces use interleaved data, while the float interfaces use deinterleaved
// data.
//
// Usage example, omitting error checking:
// AudioProcessing* apm = AudioProcessingBuilder().Create();
//
// AudioProcessing::Config config;
// config.echo_canceller.enabled = true;
// config.echo_canceller.mobile_mode = false;
//
// config.gain_controller1.enabled = true;
// config.gain_controller1.mode =
// AudioProcessing::Config::GainController1::kAdaptiveAnalog;
// config.gain_controller1.analog_level_minimum = 0;
// config.gain_controller1.analog_level_maximum = 255;
//
// config.gain_controller2.enabled = true;
//
// config.high_pass_filter.enabled = true;
//
// config.voice_detection.enabled = true;
//
// apm-&gt;ApplyConfig(config)
//
// apm-&gt;noise_reduction()-&gt;set_level(kHighSuppression);
// apm-&gt;noise_reduction()-&gt;Enable(true);
//
// // Start a voice call...
//
// // ... Render frame arrives bound for the audio HAL ...
// apm-&gt;ProcessReverseStream(render_frame);
//
// // ... Capture frame arrives from the audio HAL ...
// // Call required set_stream_ functions.
// apm-&gt;set_stream_delay_ms(delay_ms);
// apm-&gt;set_stream_analog_level(analog_level);
//
// apm-&gt;ProcessStream(capture_frame);
//
// // Call required stream_ functions.
// analog_level = apm-&gt;recommended_stream_analog_level();
// has_voice = apm-&gt;stream_has_voice();
//
// // Repeat render and capture processing for the duration of the call...
// // Start a new call...
// apm-&gt;Initialize();
//
// // Close the application...
// delete apm;
//</doc>
<fun r='_ZN6webrtc15AudioProcessingD1Ev'/>
<fun r='_ZN6webrtc15AudioProcessing10InitializeEv'/>
<fun r='_ZN6webrtc15AudioProcessing10InitializeERKNS_16ProcessingConfigE'/>
<fun r='_ZN6webrtc15AudioProcessing10InitializeEiiiNS0_13ChannelLayoutES1_S1_'/>
<fun r='_ZN6webrtc15AudioProcessing11ApplyConfigERKNS0_6ConfigE'/>
<fun r='_ZNK6webrtc15AudioProcessing19proc_sample_rate_hzEv'/>
<fun r='_ZNK6webrtc15AudioProcessing25proc_split_sample_rate_hzEv'/>
<fun r='_ZNK6webrtc15AudioProcessing18num_input_channelsEv'/>
<fun r='_ZNK6webrtc15AudioProcessing17num_proc_channelsEv'/>
<fun r='_ZNK6webrtc15AudioProcessing19num_output_channelsEv'/>
<fun r='_ZNK6webrtc15AudioProcessing20num_reverse_channelsEv'/>
<fun r='_ZN6webrtc15AudioProcessing24set_output_will_be_mutedEb'/>
<fun r='_ZN6webrtc15AudioProcessing17SetRuntimeSettingENS0_14RuntimeSettingE'/>
<fun r='_ZN6webrtc15AudioProcessing18PostRuntimeSettingENS0_14RuntimeSettingE'/>
<fun r='_ZN6webrtc15AudioProcessing13ProcessStreamEPKsRKNS_12StreamConfigES5_Ps'/>
<fun r='_ZN6webrtc15AudioProcessing13ProcessStreamEPKPKfRKNS_12StreamConfigES7_PKPf'/>
<fun r='_ZN6webrtc15AudioProcessing20ProcessReverseStreamEPKsRKNS_12StreamConfigES5_Ps'/>
<fun r='_ZN6webrtc15AudioProcessing20ProcessReverseStreamEPKPKfRKNS_12StreamConfigES7_PKPf'/>
<fun r='_ZN6webrtc15AudioProcessing20AnalyzeReverseStreamEPKPKfRKNS_12StreamConfigE'/>
<fun r='_ZNK6webrtc15AudioProcessing18GetLinearAecOutputEN3rtc9ArrayViewINSt3__15arrayIfLm160EEELln4711EEE'/>
<fun r='_ZN6webrtc15AudioProcessing23set_stream_analog_levelEi'/>
<fun r='_ZNK6webrtc15AudioProcessing31recommended_stream_analog_levelEv'/>
<fun r='_ZN6webrtc15AudioProcessing19set_stream_delay_msEi'/>
<fun r='_ZNK6webrtc15AudioProcessing15stream_delay_msEv'/>
<fun r='_ZN6webrtc15AudioProcessing22set_stream_key_pressedEb'/>
<fun r='_ZN6webrtc15AudioProcessing22CreateAndAttachAecDumpERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEExPN3rtc9TaskQueueE'/>
<fun r='_ZN6webrtc15AudioProcessing22CreateAndAttachAecDumpEP7__sFILExPN3rtc9TaskQueueE'/>
<fun r='_ZN6webrtc15AudioProcessing13AttachAecDumpENSt3__110unique_ptrINS_7AecDumpENS1_14default_deleteIS3_EEEE'/>
<fun r='_ZN6webrtc15AudioProcessing13DetachAecDumpEv'/>
<fun r='_ZN6webrtc15AudioProcessing13GetStatisticsEv'/>
<fun r='_ZN6webrtc15AudioProcessing13GetStatisticsEb'/>
<fun r='_ZNK6webrtc15AudioProcessing9GetConfigEv'/>
<smbr r='webrtc::AudioProcessing::kNativeSampleRatesHz' t='int const[4]'/>
<smbr r='webrtc::AudioProcessing::kNumNativeSampleRates' t='const size_t'/>
<smbr r='webrtc::AudioProcessing::kMaxNativeSampleRateHz' t='const int'/>
<smbr r='webrtc::AudioProcessing::kChunkSizeMs' t='const int'/>
<use f='webkit/WebKitBuild/Debug/usr/local/include/webrtc/api/create_peerconnection_factory.h' l='51' c='_ZN6webrtc27CreatePeerConnectionFactoryEPN3rtc6ThreadES2_S2_NS0_13scoped_refptrINS_17AudioDeviceModuleEEENS3_INS_19AudioEncoderFactoryEEENS3_INS_19Aud1345794'/>
<size>8</size>
