<dec f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_device/fine_audio_buffer.h' l='63' type='void webrtc::FineAudioBuffer::DeliverRecordedData(rtc::ArrayView&lt;const int16_t&gt; audio_buffer, int record_delay_ms)'/>
<def f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_device/fine_audio_buffer.cc' l='108' ll='128' type='void webrtc::FineAudioBuffer::DeliverRecordedData(rtc::ArrayView&lt;const int16_t&gt; audio_buffer, int record_delay_ms)'/>
<doc f='webkit/Source/ThirdParty/libwebrtc/Source/webrtc/modules/audio_device/fine_audio_buffer.h' l='54'>// Consumes the audio data in |audio_buffer| and sends it to the WebRTC layer
  // in chunks of 10ms. The sum of the provided delay estimate in
  // |record_delay_ms| and the latest |playout_delay_ms| in GetPlayoutData()
  // are given to the AEC in the audio processing module.
  // They can be fixed values on most platforms and they are ignored if an
  // external (hardware/built-in) AEC is used.
  // Example: buffer size is 5ms =&gt; call #1 stores 5ms of data, call #2 stores
  // 5ms of data and sends a total of 10ms to WebRTC and clears the internal
  // cache. Call #3 restarts the scheme above.</doc>
